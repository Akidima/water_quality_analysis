{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 Â· Compare Before & After Cleaning\n",
        "\n",
        "This notebook visualizes how the production cleaner transforms the dataset, highlighting wins in data quality and any trade-offs introduced by stricter rules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook goals\n",
        "\n",
        "- Quantify improvements in missing data, duplicates, and quality metrics\n",
        "- Visualize numeric distributions before vs. after cleaning\n",
        "- Demonstrate the geographic impact of coordinate validation\n",
        "- Provide an audit trail using `CleaningReport` artifacts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import importlib.util\n",
        "import sys\n",
        "\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use(\"seaborn-v0_8\")\n",
        "sns.set_theme(style=\"ticks\")\n",
        "pd.set_option(\"display.max_columns\", 40)\n",
        "\n",
        "PROJECT_ROOT = Path.cwd().resolve().parents[1]\n",
        "DATA_PATH = PROJECT_ROOT / \"data\" / \"national_water_plan.csv\"\n",
        "SCRIPTS_DIR = PROJECT_ROOT / \"scripts\"\n",
        "\n",
        "\n",
        "def load_module(module_name: str, file_path: Path):\n",
        "    if module_name in sys.modules:\n",
        "        return sys.modules[module_name]\n",
        "    spec = importlib.util.spec_from_file_location(module_name, file_path)\n",
        "    module = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[module_name] = module\n",
        "    spec.loader.exec_module(module)\n",
        "    return module\n",
        "\n",
        "\n",
        "data_loader = load_module(\"project_data_loader\", SCRIPTS_DIR / \"data-loader.py\")\n",
        "DataLoader = data_loader.DataLoader\n",
        "DataConfig = data_loader.DataConfig\n",
        "\n",
        "\n",
        "data_cleaner = load_module(\"project_data_cleaner\", SCRIPTS_DIR / \"data-cleaner.py\")\n",
        "DataCleanerConfig = data_cleaner.DataCleanerConfig\n",
        "WaterDataCleaner = data_cleaner.WaterDataCleaner\n",
        "CleaningReport = data_cleaner.CleaningReport\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load raw data & create paired samples\n",
        "\n",
        "We reuse the DataLoader to keep validation consistent, then grab a manageable slice for plotting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_config = DataConfig(filepath=str(DATA_PATH))\n",
        "loader = DataLoader(data_config)\n",
        "raw_ddf, exploration_report = loader.load_and_explore_data()\n",
        "\n",
        "SAMPLE_ROWS = 15_000\n",
        "raw_sample_pdf = raw_ddf.head(SAMPLE_ROWS, compute=True)\n",
        "print(f\"Sample rows: {len(raw_sample_pdf):,} / {exploration_report.metadata.rows:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Run the cleaner with a representative config\n",
        "\n",
        "Mirror the production defaults (strict mode, duplicates removal, coordinate checks) but skip filesystem writes for notebook speed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison_config = DataCleanerConfig(\n",
        "    strict_mode=True,\n",
        "    remove_duplicates=True,\n",
        "    remove_outliers=True,\n",
        "    outlier_std_threshold=3.0,\n",
        "    min_valid_spill_years=3,\n",
        "    fill_missing_values=False,\n",
        "    create_backup=False,\n",
        "    save_cleaning_report=False,\n",
        ")\n",
        "\n",
        "cleaner = WaterDataCleaner(comparison_config)\n",
        "cleaned_ddf, cleaning_report = cleaner.clean_data(raw_sample_pdf.copy(), output_dir=None)\n",
        "clean_sample_pdf = cleaned_ddf.compute()\n",
        "print(f\"Rows before: {len(raw_sample_pdf):,}\")\n",
        "print(f\"Rows after:  {len(clean_sample_pdf):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Summary metrics\n",
        "\n",
        "Capture missing %, duplicates, and memory footprint for the paired dataframes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def summarize_frame(df: pd.DataFrame) -> dict:\n",
        "    total_cells = df.shape[0] * df.shape[1]\n",
        "    missing_pct = (df.isna().sum().sum() / total_cells * 100) if total_cells else 0\n",
        "    duplicate_rows = df.duplicated().sum()\n",
        "    memory_mb = df.memory_usage(deep=True).sum() / 1e6\n",
        "    return {\n",
        "        \"rows\": df.shape[0],\n",
        "        \"columns\": df.shape[1],\n",
        "        \"missing_pct\": missing_pct,\n",
        "        \"duplicate_rows\": duplicate_rows,\n",
        "        \"memory_mb\": memory_mb,\n",
        "    }\n",
        "\n",
        "comparison_summary = pd.DataFrame(\n",
        "    {\n",
        "        \"raw\": summarize_frame(raw_sample_pdf),\n",
        "        \"cleaned\": summarize_frame(clean_sample_pdf),\n",
        "    }\n",
        ").transpose()\n",
        "comparison_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_metrics = pd.Series(cleaning_report.quality_metrics)\n",
        "display(report_metrics.to_frame(\"value\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Missingness per key column\n",
        "\n",
        "Visualize how missing percentages changed for critical columns from the cleaner's config.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "key_columns = [\n",
        "    col for col in sorted(set(comparison_config.required_columns + comparison_config.optional_columns))\n",
        "    if col in raw_sample_pdf.columns\n",
        "]\n",
        "missing_compare = pd.DataFrame(\n",
        "    {\n",
        "        \"raw\": raw_sample_pdf[key_columns].isna().mean() * 100,\n",
        "        \"cleaned\": clean_sample_pdf[key_columns].isna().mean() * 100,\n",
        "    }\n",
        ").reset_index().rename(columns={\"index\": \"column\"})\n",
        "\n",
        "missing_compare = missing_compare.melt(id_vars=\"column\", value_name=\"missing_pct\", var_name=\"dataset\")\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "sns.barplot(data=missing_compare, x=\"missing_pct\", y=\"column\", hue=\"dataset\", ax=ax)\n",
        "ax.set_xlabel(\"Missing (%)\")\n",
        "ax.set_ylabel(\"Column\")\n",
        "ax.set_title(\"Missing percentage before vs. after cleaning\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spill event distribution shift\n",
        "\n",
        "Pick a representative year to illustrate how outlier removal and missing handling reshape the values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_spill_col = next((col for col in comparison_config.spill_year_columns if col in raw_sample_pdf.columns), None)\n",
        "if target_spill_col:\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    sns.histplot(\n",
        "        raw_sample_pdf[target_spill_col].dropna(),\n",
        "        bins=30,\n",
        "        color=\"#9ecae1\",\n",
        "        label=\"Raw\",\n",
        "        ax=ax,\n",
        "        stat=\"density\",\n",
        "        alpha=0.6,\n",
        "    )\n",
        "    sns.histplot(\n",
        "        clean_sample_pdf[target_spill_col].dropna(),\n",
        "        bins=30,\n",
        "        color=\"#08519c\",\n",
        "        label=\"Cleaned\",\n",
        "        ax=ax,\n",
        "        stat=\"density\",\n",
        "        alpha=0.5,\n",
        "    )\n",
        "    ax.set_title(f\"{target_spill_col} distribution\")\n",
        "    ax.set_xlabel(\"Spill events\")\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No spill event columns found in the sample.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Geographic footprint\n",
        "\n",
        "Use side-by-side scatter plots to see how invalid coordinates were removed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "coord_cols = [col for col in [\"Latitude\", \"Longitude\"] if col in raw_sample_pdf.columns]\n",
        "if len(coord_cols) == 2:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
        "    raw_coords = raw_sample_pdf.dropna(subset=coord_cols)\n",
        "    clean_coords = clean_sample_pdf.dropna(subset=coord_cols)\n",
        "\n",
        "    axes[0].scatter(\n",
        "        raw_coords[\"Longitude\"],\n",
        "        raw_coords[\"Latitude\"],\n",
        "        s=8,\n",
        "        alpha=0.3,\n",
        "        color=\"#fd8d3c\",\n",
        "    )\n",
        "    axes[0].set_title(\"Raw coordinates\")\n",
        "    axes[0].set_xlabel(\"Longitude\")\n",
        "    axes[0].set_ylabel(\"Latitude\")\n",
        "\n",
        "    axes[1].scatter(\n",
        "        clean_coords[\"Longitude\"],\n",
        "        clean_coords[\"Latitude\"],\n",
        "        s=8,\n",
        "        alpha=0.3,\n",
        "        color=\"#31a354\",\n",
        "    )\n",
        "    axes[1].set_title(\"Cleaned coordinates\")\n",
        "    axes[1].set_xlabel(\"Longitude\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Latitude/Longitude columns are not both available in the sample.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Water company coverage\n",
        "\n",
        "Check whether the cleaning steps disproportionately impact specific companies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"Water company\" in raw_sample_pdf.columns:\n",
        "    raw_counts = raw_sample_pdf[\"Water company\"].value_counts().head(10)\n",
        "    clean_counts = clean_sample_pdf[\"Water company\"].value_counts().head(10)\n",
        "\n",
        "    comparison = (\n",
        "        pd.concat([raw_counts, clean_counts], axis=1, keys=[\"raw\", \"cleaned\"])\n",
        "        .fillna(0)\n",
        "        .astype(int)\n",
        "    )\n",
        "    comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Removal breakdown & audit trail\n",
        "\n",
        "Leverage the `CleaningReport` to explain exactly why rows were removed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.Series(cleaning_report.removal_breakdown).to_frame(\"rows_removed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(\n",
        "    {\n",
        "        \"errors\": cleaning_report.errors or [],\n",
        "        \"warnings\": cleaning_report.warnings or [],\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Takeaways\n",
        "\n",
        "- Pair these visuals with `export/cleaned_data` samples when presenting to stakeholders.\n",
        "- Removal breakdown + company coverage highlights whether specific regions/companies need bespoke thresholds.\n",
        "- Use this notebook as a regression harness whenever `WaterDataCleaner` logic changes.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
