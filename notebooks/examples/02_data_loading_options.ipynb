{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading Options (DataLoader)\n",
    "\n",
    "This notebook demonstrates different configuration patterns for `scripts/data-loader.py`, showcasing how chunk sizes, selective column loading, and dtype optimization flags influence runtime behavior. Use it as a playground when deciding which options fit your workflow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You'll Learn\n",
    "\n",
    "- How to dynamically import the loader module from a notebook\n",
    "- How to compare multiple `DataConfig` settings in a single session\n",
    "- How to capture summary metadata (rows, columns, memory) for each scenario\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:52:13.371086Z",
     "iopub.status.busy": "2025-11-21T09:52:13.370617Z",
     "iopub.status.idle": "2025-11-21T09:52:14.479287Z",
     "shell.execute_reply": "2025-11-21T09:52:14.478307Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import logging\n",
    "import importlib.util\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    NOTEBOOK_DIR = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent.parent\n",
    "SCRIPTS_DIR = PROJECT_ROOT / \"scripts\"\n",
    "DATA_FILE = PROJECT_ROOT / \"data\" / \"national_water_plan.csv\"\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s - %(message)s\")\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data file:    {DATA_FILE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:52:14.541467Z",
     "iopub.status.busy": "2025-11-21T09:52:14.541036Z",
     "iopub.status.idle": "2025-11-21T09:52:16.008071Z",
     "shell.execute_reply": "2025-11-21T09:52:16.007367Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_loader_module(module_name: str = \"data_loader_demo\"):\n",
    "    module_path = SCRIPTS_DIR / \"data-loader.py\"\n",
    "    spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "\n",
    "data_loader_module = load_data_loader_module()\n",
    "DataConfig = data_loader_module.DataConfig\n",
    "DataLoader = data_loader_module.DataLoader\n",
    "\n",
    "print(\"Data loader module imported successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Helper\n",
    "\n",
    "We'll define a reusable helper that runs the loader with a specific `DataConfig` and captures execution time plus key metadata.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:52:16.014110Z",
     "iopub.status.busy": "2025-11-21T09:52:16.013107Z",
     "iopub.status.idle": "2025-11-21T09:52:16.021231Z",
     "shell.execute_reply": "2025-11-21T09:52:16.020425Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_scenario(name: str, **config_kwargs):\n",
    "    \"\"\"Run the DataLoader with a custom configuration and collect summary stats.\"\"\"\n",
    "    print(f\"\\nRunning scenario: {name}\")\n",
    "    config = DataConfig(filepath=str(DATA_FILE), **config_kwargs)\n",
    "    loader = DataLoader(config=config)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    df, report = loader.load_and_explore_data()\n",
    "    duration = time.perf_counter() - start\n",
    "\n",
    "    metadata = report.metadata\n",
    "    summary = {\n",
    "        \"scenario\": name,\n",
    "        \"chunk_size\": config.chunk_size or \"auto\",\n",
    "        \"columns_loaded\": \"All\" if not config.usecols else \", \".join(config.usecols),\n",
    "        \"dtype_optimization\": config.dtype_optimization,\n",
    "        \"rows\": metadata.rows,\n",
    "        \"columns\": metadata.columns,\n",
    "        \"memory_mb\": round(metadata.memory_usage, 2),\n",
    "        \"missing_pct\": round(metadata.missing_values_percent, 2),\n",
    "        \"duplicate_rows\": metadata.duplicate_rows,\n",
    "        \"warnings\": len(report.warnings),\n",
    "        \"errors\": len(report.errors),\n",
    "        \"duration_sec\": round(duration, 2),\n",
    "    }\n",
    "\n",
    "    return summary, df, report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Multiple Configurations\n",
    "\n",
    "Feel free to edit the scenarios below. Each run will capture metadata so you can easily compare the trade-offs between different settings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:52:16.024601Z",
     "iopub.status.busy": "2025-11-21T09:52:16.024264Z",
     "iopub.status.idle": "2025-11-21T09:53:39.886066Z",
     "shell.execute_reply": "2025-11-21T09:53:39.884825Z"
    }
   },
   "outputs": [],
   "source": [
    "scenarios = [\n",
    "    {\n",
    "        \"name\": \"Default load (auto)\",\n",
    "        \"config\": {}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Chunked selective columns\",\n",
    "        \"config\": {\n",
    "            \"chunk_size\": 10_000,\n",
    "            \"usecols\": [\n",
    "                \"ID\",\n",
    "                \"Water company\",\n",
    "                \"Site name\",\n",
    "                \"River Basin District\",\n",
    "                \"Spill Events 2022\",\n",
    "                \"Sewage Reduction Plan Targets Met Flag\"\n",
    "            ],\n",
    "            \"required_columns\": [\"ID\", \"Site name\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Full dataset (dtype optimization off)\",\n",
    "        \"config\": {\n",
    "            \"dtype_optimization\": False\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "scenario_summaries = []\n",
    "scenario_outputs = {}\n",
    "\n",
    "for scenario in scenarios:\n",
    "    summary, df_obj, report = run_scenario(scenario[\"name\"], **scenario[\"config\"])\n",
    "    scenario_summaries.append(summary)\n",
    "    scenario_outputs[scenario[\"name\"]] = {\"df\": df_obj, \"report\": report}\n",
    "\n",
    "summary_df = pd.DataFrame(scenario_summaries)\n",
    "summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:53:39.889339Z",
     "iopub.status.busy": "2025-11-21T09:53:39.888993Z",
     "iopub.status.idle": "2025-11-21T09:53:39.895433Z",
     "shell.execute_reply": "2025-11-21T09:53:39.894744Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, outputs in scenario_outputs.items():\n",
    "    report = outputs[\"report\"]\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"-\" * len(name))\n",
    "    if report.warnings:\n",
    "        for warning in report.warnings:\n",
    "            print(f\"  ⚠️  {warning}\")\n",
    "    else:\n",
    "        print(\"  No warnings\")\n",
    "\n",
    "    if report.errors:\n",
    "        for error in report.errors:\n",
    "            print(f\"  ❌ {error}\")\n",
    "    else:\n",
    "        print(\"  No errors\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect a Specific Scenario\n",
    "\n",
    "Use the snippet below to inspect the Dask DataFrame returned by any of the scenarios (here we use the chunked example).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T09:53:39.899619Z",
     "iopub.status.busy": "2025-11-21T09:53:39.899068Z",
     "iopub.status.idle": "2025-11-21T09:53:40.041892Z",
     "shell.execute_reply": "2025-11-21T09:53:40.040440Z"
    }
   },
   "outputs": [],
   "source": [
    "chunked_df = scenario_outputs[\"Chunked selective columns\"][\"df\"]\n",
    "chunked_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Tweak the `scenarios` list to try other combinations (e.g., stricter `max_memory_mb`, different subsets of columns, or `required_columns` checks)\n",
    "- Persist whichever configuration works best for your pipeline inside `load_data.py` or downstream scripts\n",
    "- Pair these scenarios with the cleaning pipeline to compare performance end-to-end\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
